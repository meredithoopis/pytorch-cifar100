{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from conf import global_settings \n",
    "from model_opt import  evaluate, model_size, create_profiler \n",
    "from copy import deepcopy\n",
    "from utils import get_test_dataloader\n",
    "#from models.vgg import vgg19_bn\n",
    "from torch.nn.utils.fusion import fuse_conv_bn_eval\n",
    "from torch.quantization import quantize_dynamic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model, testloader, device, input = None): \n",
    "    if not input:\n",
    "        input = torch.randn((1,1,64,64), device = device) \n",
    "\n",
    "    top1error, top5error, t= evaluate(device, testloader, model= model, onnx = False, ort_session=None)\n",
    "    print(f\"Top-1 error: {top1error}\")\n",
    "    print(f\"Top-5 error: {top5error}\")\n",
    "    print(f\"Time per image: {t} ms\")\n",
    "    size_model = model_size(model)\n",
    "    print(f\"Model size: {size_model/1e3} MB\")\n",
    "    create_profiler(model, input, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "cfg = {\n",
    "    'A' : [64,     'M', 128,      'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
    "    'B' : [64, 64, 'M', 128, 128, 'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
    "    'D' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256,      'M', 512, 512, 512,      'M', 512, 512, 512,      'M'],\n",
    "    'E' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_class=952):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.features(x)\n",
    "        output = output.reshape(output.size()[0], -1)  # Changed from .view to .reshape\n",
    "        output = self.classifier(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    input_channel = 1  \n",
    "    for l in cfg:\n",
    "        if l == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            continue\n",
    "\n",
    "        layers += [nn.Conv2d(input_channel, l, kernel_size=3, padding=1)]\n",
    "\n",
    "        if batch_norm:\n",
    "            layers += [nn.BatchNorm2d(l)]\n",
    "\n",
    "        layers += [nn.ReLU(inplace=True)]\n",
    "        input_channel = l\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def vgg11_bn():\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True))\n",
    "\n",
    "def vgg13_bn():\n",
    "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
    "\n",
    "def vgg16_bn():\n",
    "    return VGG(make_layers(cfg['D'], batch_norm=True))\n",
    "\n",
    "def vgg19_bn():\n",
    "    return VGG(make_layers(cfg['E'], batch_norm=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "test_loader = get_test_dataloader(\n",
    "        root_dir='data/chinese_char/952_test',\n",
    "        batch_size=16,\n",
    "        num_workers=4,\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18705/2163417794.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  baseline_model.load_state_dict(torch.load('checkpoint/vgg19/Thursday_11_July_2024_15h_22m_43s/vgg19-80-best.pth' , map_location='cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = vgg19_bn()\n",
    "baseline_model.load_state_dict(torch.load('checkpoint/vgg19/Thursday_11_July_2024_15h_22m_43s/vgg19-80-best.pth' , map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 1015/1015 [04:56<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 error: 0.001970946788787842\n",
      "Top-5 error: 0.00030797719955444336\n",
      "Time per image: 18.11855486620527 ms\n",
      "Model size: 196.508568 MB\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::empty         0.94%     314.211us         0.94%     314.211us       2.455us       9.87 Mb       9.87 Mb           128  \n",
      "                     aten::conv2d         0.35%     117.108us        74.38%      24.753ms       1.547ms       4.62 Mb           0 b            16  \n",
      "                aten::convolution         0.91%     303.076us        74.03%      24.636ms       1.540ms       4.62 Mb           0 b            16  \n",
      "               aten::_convolution         0.63%     209.324us        73.12%      24.333ms       1.521ms       4.62 Mb           0 b            16  \n",
      "                 aten::batch_norm         0.20%      65.008us         3.95%       1.315ms      82.185us       4.62 Mb           0 b            16  \n",
      "     aten::_batch_norm_impl_index         0.35%     117.246us         3.76%       1.250ms      78.122us       4.62 Mb           0 b            16  \n",
      "          aten::native_batch_norm         2.68%     890.534us         3.30%       1.099ms      68.691us       4.62 Mb     -43.00 Kb            16  \n",
      "                 aten::empty_like         0.19%      64.382us         0.32%     106.736us       6.671us       4.62 Mb           0 b            16  \n",
      "         aten::mkldnn_convolution        53.87%      17.925ms        54.29%      18.066ms       1.807ms       3.38 Mb           0 b            10  \n",
      "                 aten::max_pool2d         0.09%      30.463us         4.98%       1.656ms     331.199us       1.43 Mb           0 b             5  \n",
      "    aten::max_pool2d_with_indices         4.88%       1.626ms         4.88%       1.626ms     325.107us       1.43 Mb       1.43 Mb             5  \n",
      "                aten::thnn_conv2d         0.14%      45.568us        18.19%       6.053ms       1.009ms       1.25 Mb           0 b             6  \n",
      "       aten::_slow_conv2d_forward        17.03%       5.668ms        18.05%       6.008ms       1.001ms       1.25 Mb      -1.83 Mb             6  \n",
      "                    aten::resize_         0.10%      32.062us         0.10%      32.062us       2.004us       1.25 Mb       1.25 Mb            16  \n",
      "                     aten::linear         0.07%      22.927us        15.24%       5.071ms       1.690ms      35.72 Kb           0 b             3  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 33.277ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(baseline_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 1015/1015 [04:26<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 error: 0.001970946788787842\n",
      "Top-5 error: 0.00030797719955444336\n",
      "Time per image: 16.23766715669315 ms\n",
      "Model size: 196.51065 MB\n",
      "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                              Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                       aten::empty         0.98%     299.071us         0.98%     299.071us       2.283us       9.87 Mb       9.87 Mb           131  \n",
      "                      aten::conv2d         0.28%      86.099us        80.35%      24.604ms       1.538ms       4.62 Mb           0 b            16  \n",
      "                 aten::convolution         0.79%     241.881us        80.07%      24.518ms       1.532ms       4.62 Mb           0 b            16  \n",
      "                aten::_convolution         0.57%     173.869us        79.28%      24.276ms       1.517ms       4.62 Mb           0 b            16  \n",
      "                  aten::batch_norm         0.19%      57.493us         3.88%       1.187ms      74.190us       4.62 Mb           0 b            16  \n",
      "      aten::_batch_norm_impl_index         0.37%     112.412us         3.69%       1.130ms      70.597us       4.62 Mb           0 b            16  \n",
      "           aten::native_batch_norm         2.61%     799.683us         3.22%     984.615us      61.538us       4.62 Mb     -43.00 Kb            16  \n",
      "                  aten::empty_like         0.18%      54.689us         0.32%      97.837us       6.115us       4.62 Mb           0 b            16  \n",
      "          aten::mkldnn_convolution        59.66%      18.268ms        60.11%      18.408ms       1.841ms       3.38 Mb           0 b            10  \n",
      "                  aten::max_pool2d         0.08%      24.058us         5.27%       1.612ms     322.464us       1.43 Mb           0 b             5  \n",
      "     aten::max_pool2d_with_indices         5.19%       1.588ms         5.19%       1.588ms     317.653us       1.43 Mb       1.43 Mb             5  \n",
      "                     aten::resize_         0.15%      47.030us         0.15%      47.030us       2.475us       1.28 Mb       1.28 Mb            19  \n",
      "                 aten::thnn_conv2d         0.16%      49.195us        18.58%       5.690ms     948.268us       1.25 Mb           0 b             6  \n",
      "        aten::_slow_conv2d_forward        17.54%       5.372ms        18.42%       5.640ms     940.069us       1.25 Mb      -1.83 Mb             6  \n",
      "    quantized::linear_dynamic_fp16         8.71%       2.667ms         8.98%       2.749ms     916.187us      35.72 Kb           0 b             3  \n",
      "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 30.622ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Quantize: Post training weight only quantization \n",
    "model_quantized_dynamic_float16 = quantize_dynamic(\n",
    "    model=baseline_model, qconfig_spec={torch.nn.Linear}, dtype=torch.float16,\n",
    ")\n",
    "report(model_quantized_dynamic_float16, test_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 1015/1015 [04:25<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 error: 0.001970946788787842\n",
      "Top-5 error: 0.00030797719955444336\n",
      "Time per image: 16.176997440499782 ms\n",
      "Model size: 109.31513000000001 MB\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::empty         1.17%     347.078us         1.17%     347.078us       2.590us       9.94 Mb       9.94 Mb           134  \n",
      "                 aten::empty_like         0.23%      67.829us         0.43%     129.012us       6.790us       4.66 Mb           0 b            19  \n",
      "                     aten::conv2d         0.30%      88.707us        83.39%      24.735ms       1.546ms       4.62 Mb           0 b            16  \n",
      "                aten::convolution         0.82%     243.277us        83.09%      24.647ms       1.540ms       4.62 Mb           0 b            16  \n",
      "               aten::_convolution         0.60%     176.811us        82.27%      24.403ms       1.525ms       4.62 Mb           0 b            16  \n",
      "                 aten::batch_norm         0.19%      57.386us         4.15%       1.232ms      76.996us       4.62 Mb           0 b            16  \n",
      "     aten::_batch_norm_impl_index         0.38%     112.446us         3.96%       1.175ms      73.410us       4.62 Mb           0 b            16  \n",
      "          aten::native_batch_norm         2.80%     831.353us         3.47%       1.030ms      64.373us       4.62 Mb     -43.00 Kb            16  \n",
      "         aten::mkldnn_convolution        62.60%      18.570ms        63.15%      18.734ms       1.873ms       3.38 Mb           0 b            10  \n",
      "                 aten::max_pool2d         0.09%      26.459us         5.43%       1.610ms     322.075us       1.43 Mb           0 b             5  \n",
      "    aten::max_pool2d_with_indices         5.34%       1.584ms         5.34%       1.584ms     316.783us       1.43 Mb       1.43 Mb             5  \n",
      "                aten::thnn_conv2d         0.13%      38.014us        18.50%       5.488ms     914.700us       1.25 Mb           0 b             6  \n",
      "       aten::_slow_conv2d_forward        17.41%       5.163ms        18.37%       5.450ms     908.364us       1.25 Mb      -1.83 Mb             6  \n",
      "                    aten::resize_         0.11%      31.956us         0.11%      31.956us       1.997us       1.25 Mb       1.25 Mb            16  \n",
      "        quantized::linear_dynamic         5.24%       1.554ms         5.37%       1.593ms     530.946us      35.72 Kb     -35.72 Kb             3  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 29.664ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_quantized_dynamic_int8 = quantize_dynamic(\n",
    "    model=baseline_model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8,\n",
    ")\n",
    "report(model_quantized_dynamic_int8, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.fusion import fuse_conv_bn_eval\n",
    "\n",
    "\n",
    "def fuse_all_conv_bn(model):\n",
    "    stack = []\n",
    "    for name, module in model.named_children(): # immediate children\n",
    "        if list(module.named_children()): # is not empty (not a leaf)\n",
    "            fuse_all_conv_bn(module)\n",
    "\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            if isinstance(stack[-1][1], nn.Conv2d):\n",
    "                setattr(model, stack[-1][0], fuse_conv_bn_eval(stack[-1][1], module))\n",
    "                setattr(model, name, nn.Identity())\n",
    "        else:\n",
    "            stack.append((name, module))\n",
    "\n",
    "def ptq(model, sample_loader, device='cpu', backend='fbgemm', fuse_bn=True):\n",
    "    # running on a x86 CPU. Use backend=\"qnnpack\" if running on ARM.\n",
    "    m = deepcopy(model)\n",
    "    m.eval()\n",
    "\n",
    "    # Fuse\n",
    "    if fuse_bn:\n",
    "        fuse_all_conv_bn(m)\n",
    "\n",
    "    # Insert stubs\n",
    "    m = nn.Sequential(\n",
    "        torch.quantization.QuantStub(),\n",
    "        m,\n",
    "        torch.quantization.DeQuantStub()\n",
    "    )\n",
    "\n",
    "    # Prepare\n",
    "    m.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "    torch.quantization.prepare(m, inplace=True)\n",
    "\n",
    "    \n",
    "    # Calibrate\n",
    "    m.to(device)\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in sample_loader:\n",
    "            data = data.to(device)\n",
    "            m(data)\n",
    "\n",
    "    # Convert\n",
    "    torch.quantization.convert(m, inplace=True)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hong-hanh/anaconda3/envs/test/lib/python3.11/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 1015/1015 [01:36<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 error: 0.0021557211875915527\n",
      "Top-5 error: 0.00030797719955444336\n",
      "Time per image: 5.769365510496491 ms\n",
      "Model size: 49.523506000000005 MB\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "    aten::_empty_affine_quantized         1.37%     159.708us         1.37%     159.708us       3.895us       2.43 Mb       2.43 Mb            41  \n",
      "                quantized::conv2d        67.04%       7.842ms        67.86%       7.939ms     496.164us       1.16 Mb           0 b            16  \n",
      "          quantized::batch_norm2d         5.69%     665.653us         8.35%     976.859us      61.054us       1.16 Mb     -43.00 Kb            16  \n",
      "                 aten::max_pool2d         0.17%      19.314us         1.17%     136.916us      27.383us     122.00 Kb           0 b             5  \n",
      "       aten::quantized_max_pool2d         0.86%     100.383us         1.01%     117.602us      23.520us     122.00 Kb           0 b             5  \n",
      "                      aten::empty         1.18%     138.463us         1.18%     138.463us       3.846us      82.44 Kb      82.44 Kb            36  \n",
      "                 aten::empty_like         0.93%     109.042us         2.02%     236.366us       7.386us      43.00 Kb           0 b            32  \n",
      "                quantized::linear        12.56%       1.470ms        12.86%       1.505ms     501.635us       8.93 Kb     -35.72 Kb             3  \n",
      "                    aten::resize_         0.11%      13.242us         0.11%      13.242us       4.414us       8.93 Kb       8.93 Kb             3  \n",
      "        aten::quantize_per_tensor         0.42%      48.806us         0.42%      48.806us      48.806us       4.00 Kb       4.00 Kb             1  \n",
      "                 aten::dequantize         0.12%      13.798us         0.15%      17.035us      17.035us       3.72 Kb           0 b             1  \n",
      "                    aten::reshape         0.13%      15.550us         0.40%      46.476us      46.476us       2.00 Kb           0 b             1  \n",
      "                      aten::clone         0.19%      22.506us         0.23%      26.330us      26.330us       2.00 Kb           0 b             1  \n",
      "                       aten::item         0.50%      58.267us         0.79%      92.887us       2.732us           0 b           0 b            34  \n",
      "        aten::_local_scalar_dense         0.30%      34.620us         0.30%      34.620us       1.018us           0 b           0 b            34  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 11.699ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_quantized_static_int8 = ptq(baseline_model, sample_loader=test_loader, device=device, backend='fbgemm', fuse_bn=False)\n",
    "report(model_quantized_static_int8, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 1015/1015 [01:28<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 error: 0.0018477439880371094\n",
      "Top-5 error: 0.00030797719955444336\n",
      "Time per image: 5.336659710581709 ms\n",
      "Model size: 49.406881999999996 MB\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "    aten::_empty_affine_quantized         1.62%     148.425us         1.62%     148.425us       5.937us       1.28 Mb       1.28 Mb            25  \n",
      "                quantized::conv2d        67.29%       6.165ms        68.75%       6.299ms     393.688us       1.16 Mb           0 b            16  \n",
      "                 aten::max_pool2d         0.22%      20.384us         1.73%     158.440us      31.688us     122.00 Kb           0 b             5  \n",
      "       aten::quantized_max_pool2d         1.20%     110.194us         1.51%     138.056us      27.611us     122.00 Kb           0 b             5  \n",
      "                      aten::empty         0.16%      15.111us         0.16%      15.111us       3.778us      39.44 Kb      39.44 Kb             4  \n",
      "                quantized::linear        17.26%       1.582ms        17.72%       1.624ms     541.218us       8.93 Kb     -35.72 Kb             3  \n",
      "                    aten::resize_         0.17%      15.222us         0.17%      15.222us       5.074us       8.93 Kb       8.93 Kb             3  \n",
      "        aten::quantize_per_tensor         0.57%      51.779us         0.57%      51.779us      51.779us       4.00 Kb       4.00 Kb             1  \n",
      "                 aten::dequantize         0.14%      12.852us         0.18%      16.176us      16.176us       3.72 Kb           0 b             1  \n",
      "                    aten::reshape         0.17%      15.325us         0.52%      47.479us      47.479us       2.00 Kb           0 b             1  \n",
      "                      aten::clone         0.25%      23.045us         0.30%      27.211us      27.211us       2.00 Kb           0 b             1  \n",
      "                       aten::item         0.09%       8.546us         0.15%      13.683us       6.841us           0 b           0 b             2  \n",
      "        aten::_local_scalar_dense         0.06%       5.137us         0.06%       5.137us       2.569us           0 b           0 b             2  \n",
      "                    aten::q_scale         0.19%      17.218us         0.19%      17.218us       0.689us           0 b           0 b            25  \n",
      "               aten::q_zero_point         0.22%      20.121us         0.22%      20.121us       0.468us           0 b           0 b            43  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 9.162ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_quantized_static_fuse_int8 = ptq(baseline_model, sample_loader=test_loader, device=device, backend='fbgemm', fuse_bn=True)\n",
    "report(model_quantized_static_fuse_int8, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
